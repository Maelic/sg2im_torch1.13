There are 7370 iterations per epoch
Sg2ImModel(
  (obj_embeddings): Embedding(152, 128)
  (pred_embeddings): Embedding(51, 128)
  (gconv): GraphTripleConv(
    (net1): Sequential(
      (0): Linear(in_features=384, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=1152, bias=True)
      (3): ReLU()
    )
    (net2): Sequential(
      (0): Linear(in_features=512, out_features=512, bias=True)
      (1): ReLU()
      (2): Linear(in_features=512, out_features=128, bias=True)
      (3): ReLU()
    )
  )
  (gconv_net): GraphTripleConvNet(
    (gconvs): ModuleList(
      (0): GraphTripleConv(
        (net1): Sequential(
          (0): Linear(in_features=384, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=1152, bias=True)
          (3): ReLU()
        )
        (net2): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=128, bias=True)
          (3): ReLU()
        )
      )
      (1): GraphTripleConv(
        (net1): Sequential(
          (0): Linear(in_features=384, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=1152, bias=True)
          (3): ReLU()
        )
        (net2): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=128, bias=True)
          (3): ReLU()
        )
      )
      (2): GraphTripleConv(
        (net1): Sequential(
          (0): Linear(in_features=384, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=1152, bias=True)
          (3): ReLU()
        )
        (net2): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=128, bias=True)
          (3): ReLU()
        )
      )
      (3): GraphTripleConv(
        (net1): Sequential(
          (0): Linear(in_features=384, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=1152, bias=True)
          (3): ReLU()
        )
        (net2): Sequential(
          (0): Linear(in_features=512, out_features=512, bias=True)
          (1): ReLU()
          (2): Linear(in_features=512, out_features=128, bias=True)
          (3): ReLU()
        )
      )
    )
  )
  (box_net): Sequential(
    (0): Linear(in_features=128, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=4, bias=True)
    (3): ReLU()
  )
  (mask_net): Sequential(
    (0): Upsample(scale_factor=2.0, mode=nearest)
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU()
    (4): Upsample(scale_factor=2.0, mode=nearest)
    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU()
    (8): Upsample(scale_factor=2.0, mode=nearest)
    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU()
    (12): Upsample(scale_factor=2.0, mode=nearest)
    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU()
    (16): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (rel_aux_net): Sequential(
    (0): Linear(in_features=264, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=51, bias=True)
    (3): ReLU()
  )
  (refinement_net): RefinementNetwork(
    (refinement_modules): ModuleList(
      (0): RefinementModule(
        (net): Sequential(
          (0): Conv2d(161, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.2)
          (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): LeakyReLU(negative_slope=0.2)
        )
      )
      (1): RefinementModule(
        (net): Sequential(
          (0): Conv2d(1184, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.2)
          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): LeakyReLU(negative_slope=0.2)
        )
      )
      (2): RefinementModule(
        (net): Sequential(
          (0): Conv2d(672, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.2)
          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): LeakyReLU(negative_slope=0.2)
        )
      )
      (3): RefinementModule(
        (net): Sequential(
          (0): Conv2d(416, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.2)
          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): LeakyReLU(negative_slope=0.2)
        )
      )
      (4): RefinementModule(
        (net): Sequential(
          (0): Conv2d(288, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): LeakyReLU(negative_slope=0.2)
          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (5): LeakyReLU(negative_slope=0.2)
        )
      )
    )
    (output_conv): Sequential(
      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): LeakyReLU(negative_slope=0.2)
      (2): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
LeakyReLU(negative_slope=0.2)
Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
LeakyReLU(negative_slope=0.2)
Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))
Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))
BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
LeakyReLU(negative_slope=0.2)
Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))
BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
LeakyReLU(negative_slope=0.2)
Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))
AcCropDiscriminator(
  (discriminator): AcDiscriminator(
    (cnn): Sequential(
      (0): Sequential(
        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.2)
        (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))
        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): LeakyReLU(negative_slope=0.2)
        (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))
      )
      (1): GlobalAvgPool()
      (2): Linear(in_features=256, out_features=1024, bias=True)
    )
    (real_classifier): Linear(in_features=1024, out_features=1, bias=True)
    (obj_classifier): Linear(in_features=1024, out_features=151, bias=True)
  )
)
PatchDiscriminator(
  (cnn): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): LeakyReLU(negative_slope=0.2)
    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2))
    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): LeakyReLU(negative_slope=0.2)
    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2))
  )
  (classifier): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
)
Starting epoch 1
  0%|                                                                                                                                                      | 0/7370 [00:00<?, ?it/s]/home/maelic/miniconda3/envs/sg2im/lib/python3.10/site-packages/torch/nn/functional.py:4227: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/maelic/miniconda3/envs/sg2im/lib/python3.10/site-packages/torch/nn/functional.py:3734: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")







  0%|â–Œ                                                                                                                                          | 32/7370 [00:25<1:37:21,  1.26it/s]
Traceback (most recent call last):
  File "/home/maelic/Documents/PhD/ModelZoo/SGG2IM/sg2im/scripts/train.py", line 690, in <module>
    main(args)
  File "/home/maelic/Documents/PhD/ModelZoo/SGG2IM/sg2im/scripts/train.py", line 574, in main
    total_loss.backward()
  File "/home/maelic/miniconda3/envs/sg2im/lib/python3.10/site-packages/torch/_tensor.py", line 488, in backward
    torch.autograd.backward(
  File "/home/maelic/miniconda3/envs/sg2im/lib/python3.10/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt